---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: human-consumer
  namespace: llama-agents-demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: human-consumer
  template:
    metadata:
      labels:
        app: human-consumer
    spec:
      containers:
        - name: human-consumer
          env:
            - name: MESSAGE_QUEUE_HOST
              valueFrom:
                configMapKeyRef:
                  name: xcore-config
                  key: MESSAGE_QUEUE_HOST
            - name: MESSAGE_QUEUE_PORT
              valueFrom:
                configMapKeyRef:
                  name: xcore-config
                  key: MESSAGE_QUEUE_PORT
            - name: CONTROL_PLANE_HOST
              valueFrom:
                configMapKeyRef:
                  name: xcore-config
                  key: CONTROL_PLANE_HOST
            - name: CONTROL_PLANE_PORT
              valueFrom:
                configMapKeyRef:
                  name: xcore-config
                  key: CONTROL_PLANE_PORT
            - name: HUMAN_CONSUMER_HOST
              valueFrom:
                configMapKeyRef:
                  name: xcore-config
                  key: HUMAN_CONSUMER_HOST
            - name: HUMAN_CONSUMER_PORT
              valueFrom:
                configMapKeyRef:
                  name: xcore-config
                  key: HUMAN_CONSUMER_PORT
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: xcore-secret
                  key: OPENAI_API_KEY
          image: multi_agent_app:latest
          imagePullPolicy: Never
          command:
            [
              "uvicorn",
              "multi_agent_app.app_human_consumer:app",
              "--host",
              "0.0.0.0",
              "--port",
              "8000",
              "--log-config",
              "./logging.ini",
              "--log-level",
              "debug",
            ]
          resources:
            requests:
              memory: "128Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          ports:
            - containerPort: 8000

---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: human-consumer
  name: human-consumer
  namespace: llama-agents-demo
spec:
  selector:
    app: human-consumer
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: human-consumer
  namespace: llama-agents-demo
spec:
  rules:
    - host: human-consumer.127.0.0.1.nip.io
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: human-consumer
                port:
                  number: 8000
