name: QuickStart

control-plane:
  port: 8000

default-service: echo_workflow

services:
  echo_workflow:
    name: Echo Workflow
    source:
      type: local
      name: src
    path: src/workflow:echo_workflow

ui:
  name: My Nextjs App
  starter_questions: # List of starter questions for the chat UI (default: None)
    - "What is LlamaIndex?"
    - "How do I use it with LLMs?"
  ui_path: ".ui" # Path for downloaded UI static files (default: ".ui")
  component_dir: "components" # The directory for custom UI components rendering events emitted by the workflow. The default is None, which does not render custom UI components.
  layout_dir: "layout" # The directory for custom layout sections. The default value is `layout`.
  llamacloud_index_selector: false # Whether to show the LlamaCloud index selector in the chat UI (default: False). Requires `LLAMA_CLOUD_API_KEY` to be set.
  dev_mode: false # When enabled, you can update workflow code in the UI and see the changes immediately.
  suggest_next_questions: true # Whether to suggest next questions after the assistant's response (default: True).
